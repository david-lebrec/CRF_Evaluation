{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-39-ccc7d3cf823f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmetrics\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mclassification_report\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconfusion_matrix\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreprocessing\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mLabelBinarizer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "from itertools import chain\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package conll2002 to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2002 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['esp.testa', 'esp.testb', 'esp.train', 'ned.testa', 'ned.testb', 'ned.train']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('conll2002')\n",
    "nltk.corpus.conll2002.fileids()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Melbourne', 'NP', 'B-LOC'), ('(', 'Fpa', 'O'), ('Australia', 'NP', 'B-LOC'), (')', 'Fpt', 'O'), (',', 'Fc', 'O'), ('25', 'Z', 'O'), ('may', 'NC', 'O'), ('(', 'Fpa', 'O'), ('EFE', 'NC', 'B-ORG'), (')', 'Fpt', 'O'), ('.', 'Fp', 'O')], [('-', 'Fg', 'O')], ...]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.corpus.conll2002.iob_sents('esp.train'))\n",
    "train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train'))\n",
    "test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Melbourne', 'NP', 'B-LOC'),\n",
       " ('(', 'Fpa', 'O'),\n",
       " ('Australia', 'NP', 'B-LOC'),\n",
       " (')', 'Fpt', 'O'),\n",
       " (',', 'Fc', 'O'),\n",
       " ('25', 'Z', 'O'),\n",
       " ('may', 'NC', 'O'),\n",
       " ('(', 'Fpa', 'O'),\n",
       " ('EFE', 'NC', 'B-ORG'),\n",
       " (')', 'Fpt', 'O'),\n",
       " ('.', 'Fp', 'O')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#présenter données autrement\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag,\n",
    "        'postag[:2]=' + postag[:2],\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:postag=' + postag1,\n",
    "            '-1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:postag=' + postag1,\n",
    "            '+1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [1, 3, 2, 9, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst2 = ['DAvid', 'Guillaume', 'PAris']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 2, 9]\n"
     ]
    }
   ],
   "source": [
    "print(lst[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n"
     ]
    }
   ],
   "source": [
    "print(lst[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3]\n"
     ]
    }
   ],
   "source": [
    "print(lst[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 8]\n"
     ]
    }
   ],
   "source": [
    "print(lst[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 9, 8]\n"
     ]
    }
   ],
   "source": [
    "print(lst[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 9, 8]\n"
     ]
    }
   ],
   "source": [
    "print(lst[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bias',\n",
       " 'word.lower=melbourne',\n",
       " 'word[-3:]=rne',\n",
       " 'word[-2:]=ne',\n",
       " 'word.isupper=False',\n",
       " 'word.istitle=True',\n",
       " 'word.isdigit=False',\n",
       " 'postag=NP',\n",
       " 'postag[:2]=NP',\n",
       " 'BOS',\n",
       " '+1:word.lower=(',\n",
       " '+1:word.istitle=False',\n",
       " '+1:word.isupper=False',\n",
       " '+1:postag=Fpa',\n",
       " '+1:postag[:2]=Fp']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train_sents[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer.params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train('conll2002-esp.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex‚cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!ls -lh ./conll2002-esp.crfsuite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 50,\n",
       " 'scores': {},\n",
       " 'loss': 14807.577946,\n",
       " 'feature_norm': 79.110017,\n",
       " 'error_norm': 1262.912078,\n",
       " 'active_features': 11346,\n",
       " 'linesearch_trials': 1,\n",
       " 'linesearch_step': 1.0,\n",
       " 'time': 0.277}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.logparser.last_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 {'num': 50, 'scores': {}, 'loss': 14807.577946, 'feature_norm': 79.110017, 'error_norm': 1262.912078, 'active_features': 11346, 'linesearch_trials': 1, 'linesearch_step': 1.0, 'time': 0.277}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(trainer.logparser.iterations), trainer.logparser.iterations[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x296393f5400>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('conll2002-esp.crfsuite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Coruña , 23 may ( EFECOM ) .\n",
      "\n",
      "Predicted: B-LOC I-LOC O O O O B-ORG O O\n",
      "Correct:   B-LOC I-LOC O O O O B-ORG O O\n"
     ]
    }
   ],
   "source": [
    "example_sent = test_sents[0]\n",
    "print(' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
    "\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PERS', 'B']\n",
      "{'I-MISC', 'I-ORG', 'B-LOC', 'B-MISC', 'I-LOC', 'B-ORG', 'I-PER', 'B-PER'}\n",
      "['B-LOC', 'I-LOC', 'B-MISC', 'I-MISC', 'B-ORG', 'I-ORG', 'B-PER', 'I-PER']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.78      0.75      0.76      1084\n",
      "       I-LOC       0.66      0.60      0.63       325\n",
      "      B-MISC       0.69      0.47      0.56       339\n",
      "      I-MISC       0.61      0.49      0.54       557\n",
      "       B-ORG       0.79      0.81      0.80      1400\n",
      "       I-ORG       0.80      0.79      0.80      1104\n",
      "       B-PER       0.82      0.87      0.84       735\n",
      "       I-PER       0.87      0.93      0.90       634\n",
      "\n",
      "   micro avg       0.78      0.76      0.77      6178\n",
      "   macro avg       0.75      0.71      0.73      6178\n",
      "weighted avg       0.77      0.76      0.76      6178\n",
      " samples avg       0.09      0.09      0.09      6178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\david\\pycharmprojects\\crf_evaluation\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\david\\pycharmprojects\\crf_evaluation\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "def traduction_lambda(tag):\n",
    "    tag = tag.split('-', 1)\n",
    "    return tag[::-1]\n",
    "    \n",
    "print(traduction_lambda('B-PERS'))\n",
    "    \n",
    "    \n",
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    print(tagset)\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    print(tagset)\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )\n",
    "y_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "print(bio_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst2 = [4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x0000029657817580>\n"
     ]
    }
   ],
   "source": [
    "print(zip(lst, lst2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n",
      "(2, 5)\n",
      "(3, 6)\n"
     ]
    }
   ],
   "source": [
    "for row in zip(lst, lst2):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "B-ORG  -> I-ORG   8.631963\n",
      "I-ORG  -> I-ORG   7.833706\n",
      "B-PER  -> I-PER   6.998706\n",
      "B-LOC  -> I-LOC   6.913675\n",
      "I-MISC -> I-MISC  6.129735\n",
      "B-MISC -> I-MISC  5.538291\n",
      "I-LOC  -> I-LOC   4.983567\n",
      "I-PER  -> I-PER   3.748358\n",
      "B-ORG  -> B-LOC   1.727090\n",
      "B-PER  -> B-LOC   1.388267\n",
      "B-LOC  -> B-LOC   1.240278\n",
      "O      -> O       1.197929\n",
      "O      -> B-ORG   1.097062\n",
      "I-PER  -> B-LOC   1.083332\n",
      "O      -> B-MISC  1.046113\n",
      "\n",
      "Top unlikely transitions:\n",
      "I-PER  -> B-ORG   -2.056130\n",
      "I-LOC  -> I-ORG   -2.143940\n",
      "B-ORG  -> I-MISC  -2.167501\n",
      "I-PER  -> I-ORG   -2.369380\n",
      "B-ORG  -> I-PER   -2.378110\n",
      "I-MISC -> I-PER   -2.458788\n",
      "B-LOC  -> I-PER   -2.516414\n",
      "I-ORG  -> I-MISC  -2.571973\n",
      "I-LOC  -> B-PER   -2.697791\n",
      "I-LOC  -> I-PER   -3.065950\n",
      "I-ORG  -> I-PER   -3.364434\n",
      "O      -> I-PER   -7.322841\n",
      "O      -> I-MISC  -7.648246\n",
      "O      -> I-ORG   -8.024126\n",
      "O      -> I-LOC   -8.333815\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "info = tagger.info()\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common(15))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common()[-15:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guillaume -> personne 82.500000\n"
     ]
    }
   ],
   "source": [
    "print(\"%-3s -> %-4s %0.6f\" % ('guillaume', 'personne', 82.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "8.886516 B-ORG  word.lower=efe-cantabria\n",
      "8.743642 B-ORG  word.lower=psoe-progresistas\n",
      "5.769032 B-LOC  -1:word.lower=cantabria\n",
      "5.195429 I-LOC  -1:word.lower=calle\n",
      "5.116821 O      word.lower=mayo\n",
      "4.990871 O      -1:word.lower=día\n",
      "4.910915 I-ORG  -1:word.lower=l\n",
      "4.721572 B-MISC word.lower=diversia\n",
      "4.676259 B-ORG  word.lower=telefónica\n",
      "4.334354 B-ORG  word[-2:]=-e\n",
      "4.149862 B-ORG  word.lower=amena\n",
      "4.141370 B-ORG  word.lower=terra\n",
      "3.942852 O      word.istitle=False\n",
      "3.926397 B-ORG  word.lower=continente\n",
      "3.924672 B-ORG  word.lower=acesa\n",
      "3.888706 O      word.lower=euro\n",
      "3.856445 B-PER  -1:word.lower=según\n",
      "3.812373 B-MISC word.lower=exteriores\n",
      "3.807582 I-MISC -1:word.lower=1.9\n",
      "3.807098 B-MISC word.lower=sanidad\n",
      "\n",
      "Top negative:\n",
      "-1.965379 O      word.lower=fundación\n",
      "-1.981541 O      -1:word.lower=británica\n",
      "-2.118347 O      word.lower=061\n",
      "-2.190653 B-PER  word[-3:]=nes\n",
      "-2.226373 B-ORG  postag=SP\n",
      "-2.226373 B-ORG  postag[:2]=SP\n",
      "-2.260972 O      word[-3:]=uia\n",
      "-2.384920 O      -1:word.lower=sección\n",
      "-2.483009 O      word[-2:]=s.\n",
      "-2.535050 I-LOC  BOS\n",
      "-2.583123 O      -1:word.lower=sánchez\n",
      "-2.585756 O      postag=NP\n",
      "-2.585756 O      postag[:2]=NP\n",
      "-2.588899 O      word[-2:]=om\n",
      "-2.738583 O      -1:word.lower=carretera\n",
      "-2.913103 O      word.istitle=True\n",
      "-2.926560 O      word[-2:]=nd\n",
      "-2.946862 I-PER  -1:word.lower=san\n",
      "-2.954094 B-PER  -1:word.lower=del\n",
      "-3.529449 O      word.isupper=True\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-6s %s\" % (weight, label, attr))    \n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(info.state_features).most_common(20))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(info.state_features).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"C:\\Users\\david\\OneDrive\\Documents\\Données Data Science\\conll2003_2_bis\\train.txt\".encode(encoding='UTF-8',errors='strict')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import codecs\n",
    "\n",
    "\n",
    "doc = codecs.open(filename, 'rU', 'UTF-8')\n",
    "dataset = pd.read_csv(doc, sep='\\t', nrows=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          -DOCSTART- -X- -X- O\n",
      "0            EU NNP B-NP B-ORG\n",
      "1           rejects VBZ B-VP O\n",
      "2        German JJ B-NP B-MISC\n",
      "3               call NN I-NP O\n",
      "4                 to TO B-VP O\n",
      "...                        ...\n",
      "204561         three CD I-NP O\n",
      "204562   Swansea NN B-NP B-ORG\n",
      "204563             1 CD I-NP O\n",
      "204564  Lincoln NNP I-NP B-ORG\n",
      "204565             2 CD I-NP O\n",
      "\n",
      "[204566 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = r\"C:\\Users\\david\\OneDrive\\Documents\\Données Data Science\\conll2003_2_bis\\valid.txt\".encode(encoding='UTF-8',errors='strict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = codecs.open(filename2, 'rU', 'UTF-8')\n",
    "dataset2 = pd.read_csv(doc, sep='\\t', nrows=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                -DOCSTART- -X- -X- O\n",
      "0                 CRICKET NNP B-NP O\n",
      "1                            - : O O\n",
      "2      LEICESTERSHIRE NNP B-NP B-ORG\n",
      "3                    TAKE NNP I-NP O\n",
      "4                     OVER IN B-PP O\n",
      "...                              ...\n",
      "51572                        . . O O\n",
      "51573                       -- : O O\n",
      "51574           Dhaka NNP B-NP B-ORG\n",
      "51575        Newsroom NNP I-NP I-ORG\n",
      "51576         880-2-506363 CD I-NP O\n",
      "\n",
      "[51577 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-DOCSTART- -X- -X- O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRICKET NNP B-NP O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- : O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LEICESTERSHIRE NNP B-NP B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TAKE NNP I-NP O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OVER IN B-PP O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51572</th>\n",
       "      <td>. . O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51573</th>\n",
       "      <td>-- : O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51574</th>\n",
       "      <td>Dhaka NNP B-NP B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51575</th>\n",
       "      <td>Newsroom NNP I-NP I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51576</th>\n",
       "      <td>880-2-506363 CD I-NP O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103154 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                -DOCSTART- -X- -X- O\n",
       "0                 CRICKET NNP B-NP O\n",
       "1                            - : O O\n",
       "2      LEICESTERSHIRE NNP B-NP B-ORG\n",
       "3                    TAKE NNP I-NP O\n",
       "4                     OVER IN B-PP O\n",
       "...                              ...\n",
       "51572                        . . O O\n",
       "51573                       -- : O O\n",
       "51574           Dhaka NNP B-NP B-ORG\n",
       "51575        Newsroom NNP I-NP I-ORG\n",
       "51576         880-2-506363 CD I-NP O\n",
       "\n",
       "[103154 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.append(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'str'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-21-c32d394c427e>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mrow\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdataset2\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m     \u001B[0mdataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mignore_index\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mc:\\users\\david\\pycharmprojects\\crf_evaluation\\venv\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36mappend\u001B[1;34m(self, other, ignore_index, verify_integrity, sort)\u001B[0m\n\u001B[0;32m   7980\u001B[0m             \u001B[0mto_concat\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mother\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   7981\u001B[0m         return (\n\u001B[1;32m-> 7982\u001B[1;33m             concat(\n\u001B[0m\u001B[0;32m   7983\u001B[0m                 \u001B[0mto_concat\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   7984\u001B[0m                 \u001B[0mignore_index\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mignore_index\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\david\\pycharmprojects\\crf_evaluation\\venv\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001B[0m in \u001B[0;36mconcat\u001B[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001B[0m\n\u001B[0;32m    283\u001B[0m     \u001B[0mValueError\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mIndexes\u001B[0m \u001B[0mhave\u001B[0m \u001B[0moverlapping\u001B[0m \u001B[0mvalues\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m'a'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    284\u001B[0m     \"\"\"\n\u001B[1;32m--> 285\u001B[1;33m     op = _Concatenator(\n\u001B[0m\u001B[0;32m    286\u001B[0m         \u001B[0mobjs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    287\u001B[0m         \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\david\\pycharmprojects\\crf_evaluation\\venv\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001B[0m\n\u001B[0;32m    368\u001B[0m                     \u001B[1;34m\"only Series and DataFrame objs are valid\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    369\u001B[0m                 )\n\u001B[1;32m--> 370\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    371\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    372\u001B[0m             \u001B[1;31m# consolidate\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: cannot concatenate object of type '<class 'str'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "for row in dataset2:\n",
    "    dataset.append(row, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Melbourne', 'NP', 'B-LOC'), ('(', 'Fpa', 'O'), ('Australia', 'NP', 'B-LOC'), (')', 'Fpt', 'O'), (',', 'Fc', 'O'), ('25', 'Z', 'O'), ('may', 'NC', 'O'), ('(', 'Fpa', 'O'), ('EFE', 'NC', 'B-ORG'), (')', 'Fpt', 'O'), ('.', 'Fp', 'O')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train'))\n",
    "test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))\n",
    "print(train_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('-', 'Fg', 'O')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_sents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('El', 'DA', 'O'), ('Abogado', 'NC', 'B-PER'), ('General', 'AQ', 'I-PER'), ('del', 'SP', 'I-PER'), ('Estado', 'NC', 'I-PER'), (',', 'Fc', 'O'), ('Daryl', 'VMI', 'B-PER'), ('Williams', 'NC', 'I-PER'), (',', 'Fc', 'O'), ('subrayó', 'VMI', 'O'), ('hoy', 'RG', 'O'), ('la', 'DA', 'O'), ('necesidad', 'NC', 'O'), ('de', 'SP', 'O'), ('tomar', 'VMN', 'O'), ('medidas', 'NC', 'O'), ('para', 'SP', 'O'), ('proteger', 'VMN', 'O'), ('al', 'SP', 'O'), ('sistema', 'NC', 'O'), ('judicial', 'AQ', 'O'), ('australiano', 'AQ', 'O'), ('frente', 'RG', 'O'), ('a', 'SP', 'O'), ('una', 'DI', 'O'), ('página', 'NC', 'O'), ('de', 'SP', 'O'), ('internet', 'NC', 'O'), ('que', 'PR', 'O'), ('imposibilita', 'VMI', 'O'), ('el', 'DA', 'O'), ('cumplimiento', 'NC', 'O'), ('de', 'SP', 'O'), ('los', 'DA', 'O'), ('principios', 'NC', 'O'), ('básicos', 'AQ', 'O'), ('de', 'SP', 'O'), ('la', 'DA', 'O'), ('Ley', 'NC', 'B-MISC'), ('.', 'Fp', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(train_sents[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('La', 'DA', 'O'), ('petición', 'NC', 'O'), ('del', 'SP', 'O'), ('Abogado', 'NC', 'B-PER'), ('General', 'AQ', 'I-PER'), ('tiene', 'VMI', 'O'), ('lugar', 'NC', 'O'), ('después', 'RG', 'O'), ('de', 'SP', 'O'), ('que', 'CS', 'O'), ('un', 'DI', 'O'), ('juez', 'NC', 'O'), ('del', 'SP', 'O'), ('Tribunal', 'NC', 'B-ORG'), ('Supremo', 'AQ', 'I-ORG'), ('del', 'SP', 'O'), ('estado', 'NC', 'O'), ('de', 'SP', 'O'), ('Victoria', 'NC', 'B-LOC'), ('(', 'Fpa', 'O'), ('Australia', 'NP', 'B-LOC'), (')', 'Fpt', 'O'), ('se', 'P0', 'O'), ('viera', 'VMS', 'O'), ('forzado', 'AQ', 'O'), ('a', 'SP', 'O'), ('disolver', 'VMN', 'O'), ('un', 'DI', 'O'), ('jurado', 'NC', 'O'), ('popular', 'AQ', 'O'), ('y', 'CC', 'O'), ('suspender', 'VMN', 'O'), ('el', 'DA', 'O'), ('proceso', 'NC', 'O'), ('ante', 'SP', 'O'), ('el', 'DA', 'O'), ('argumento', 'NC', 'O'), ('de', 'SP', 'O'), ('la', 'DA', 'O'), ('defensa', 'NC', 'O'), ('de', 'SP', 'O'), ('que', 'CS', 'O'), ('las', 'DA', 'O'), ('personas', 'NC', 'O'), ('que', 'PR', 'O'), ('lo', 'PP', 'O'), ('componían', 'VMI', 'O'), ('podían', 'VMI', 'O'), ('haber', 'VAN', 'O'), ('obtenido', 'VMP', 'O'), ('información', 'NC', 'O'), ('sobre', 'SP', 'O'), ('el', 'DA', 'O'), ('acusado', 'VMP', 'O'), ('a', 'SP', 'O'), ('través', 'NC', 'O'), ('de', 'SP', 'O'), ('la', 'DA', 'O'), ('página', 'NC', 'O'), ('CrimeNet', 'AQ', 'B-MISC'), ('.', 'Fp', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(train_sents[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Esta', 'DD', 'O'), ('página', 'NC', 'O'), ('web', 'AQ', 'O'), ('lleva', 'VMI', 'O'), ('un', 'DI', 'O'), ('mes', 'NC', 'O'), ('de', 'SP', 'O'), ('existencia', 'NC', 'O'), (',', 'Fc', 'O'), ('tiempo', 'NC', 'O'), ('en', 'SP', 'O'), ('el', 'DA', 'O'), ('que', 'PR', 'O'), ('ha', 'VAI', 'O'), ('sido', 'VSP', 'O'), ('visitada', 'VMP', 'O'), ('en', 'SP', 'O'), ('más', 'RG', 'O'), ('de', 'SP', 'O'), ('un', 'DI', 'O'), ('millón', 'NC', 'O'), ('de', 'SP', 'O'), ('ocasiones', 'NC', 'O'), (',', 'Fc', 'O'), ('y', 'CC', 'O'), ('facilita', 'VMI', 'O'), ('información', 'NC', 'O'), ('sobre', 'SP', 'O'), ('miles', 'PN', 'O'), ('de', 'SP', 'O'), ('crímenes', 'NC', 'O'), ('y', 'CC', 'O'), ('criminales', 'VMM', 'O'), ('ya', 'RG', 'O'), ('enjuiciados', 'VMP', 'O'), ('o', 'CC', 'O'), ('aún', 'RG', 'O'), ('perseguidos', 'VMM', 'O'), (',', 'Fc', 'O'), ('datos', 'NC', 'O'), ('que', 'PR', 'O'), ('salen', 'VMI', 'O'), ('de', 'SP', 'O'), ('artículos', 'NC', 'O'), ('de', 'SP', 'O'), ('periódicos', 'NC', 'O'), ('y', 'CC', 'O'), ('archivos', 'NC', 'O'), ('judiciales', 'AQ', 'O'), ('.', 'Fp', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(train_sents[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helpers'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-34-c99772e64aa2>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mhelpers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDocumentHelper\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mDocumentsHelper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'helpers'"
     ]
    }
   ],
   "source": [
    "from helpers.DocumentHelper import DocumentsHelper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY: str = 'data'\n",
    "TEST_FILE_NAME: str = f'{DATA_DIRECTORY}/test.txt'\n",
    "VALID_FILE_NAME: str = f'{DATA_DIRECTORY}/valid.txt'\n",
    "SPACY_FILE_NAME: str = f'{DATA_DIRECTORY}/spacy.txt'\n",
    "\n",
    "\"\"\"\n",
    "    string management\n",
    "\"\"\"\n",
    "SPACE: str = ' '\n",
    "EMPTY: str = ''\n",
    "NEW_LINE: str = '\\n'\n",
    "OPEN_PARENTHESIS: str = '('\n",
    "END_PARENTHESIS: str = ')'\n",
    "DOT: str = '.'\n",
    "COMMA: str = ','\n",
    "COLONS: str = ':'\n",
    "SLASH: str = '/'\n",
    "QUOTE: str = \"'\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    document mnagament\n",
    "\"\"\"\n",
    "DOCUMENT_START: str = '-DOCSTART-'\n",
    "LINE_START: str = '- : O O'\n",
    "LINE_END: str = '. . O O'\n",
    "\n",
    "\"\"\"\n",
    "    data files columns\n",
    "\"\"\"\n",
    "INDEX_WORD: int = 0\n",
    "INDEX_POST_TAG: int = 2\n",
    "INDEX_ENTITY: int = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentsHelper:\n",
    "\n",
    "    def remove_last_char(self, value: str) -> str:\n",
    "        return value.rstrip(self.get_last_char(value))\n",
    "\n",
    "    def get_last_char(self, value: str) -> str:\n",
    "        if len(value) > 0:\n",
    "            return value[-1]\n",
    "        return ''\n",
    "\n",
    "    def is_parenthesis(self, value: str) -> bool:\n",
    "        return value == OPEN_PARENTHESIS or value == END_PARENTHESIS\n",
    "\n",
    "    def is_special_char_without_left_space(self, value: str) -> bool:\n",
    "        return value == COMMA or value == DOT or value == SLASH or value == QUOTE or value == END_PARENTHESIS\n",
    "\n",
    "    def is_special_char_without_right_space(self, value: str) -> bool:\n",
    "        return value == OPEN_PARENTHESIS or value == SLASH\n",
    "\n",
    "    def clean_string(self, value: str) -> str:\n",
    "        return value.replace(NEW_LINE, EMPTY).replace('\\'', \"'\")\n",
    "\n",
    "    def is_string_start_line(self, line: str) -> bool:\n",
    "        return line.__contains__(LINE_START)\n",
    "\n",
    "    def is_string_end_line(self, line: str) -> bool:\n",
    "        return line.__contains__(LINE_END)\n",
    "\n",
    "    def is_string_not_start_or_end_line(self, line: str) -> bool:\n",
    "        return not (self.is_string_start_line(line) or self.is_string_end_line(line))\n",
    "\n",
    "    def is_string_not_document_start(self, line: str) -> bool:\n",
    "        return not line.__contains__(DOCUMENT_START)\n",
    "\n",
    "    def is_string_not_empty_or_none(self, value: str) -> bool:\n",
    "       return not (value is None or value == '')\n",
    "\n",
    "    def is_valid_token(self, line: str) -> bool:\n",
    "        return self.is_string_not_empty_or_none(line) and self.is_string_not_document_start(line) and self.is_string_not_start_or_end_line(line)\n",
    "\n",
    "    def is_documents_property_empty(self, documents: list) -> bool:\n",
    "        return self.get_documents_size(documents) == 0\n",
    "\n",
    "    def get_documents_size(self, documents: list) -> int:\n",
    "        return len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_data(filename_3):\n",
    "    doc_lines = []\n",
    "    helper = DocumentsHelper()\n",
    "    file = open(filename_3, 'r')\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        #print(line)\n",
    "        split_line = line.split(SPACE)\n",
    "        #print(split_line)\n",
    "        word: str = split_line[INDEX_WORD]\n",
    "        try:\n",
    "            if helper.is_string_start_line(line):\n",
    "                doc_line = []\n",
    "            if word != NEW_LINE and not helper.is_string_end_line(line) and not helper.is_string_start_line(line):\n",
    "                entity: str = split_line[INDEX_ENTITY]\n",
    "                post_tag: str = split_line[INDEX_POST_TAG]\n",
    "                line_component = (word, post_tag, entity)\n",
    "                doc_line.append(line_component)\n",
    "            if helper.is_string_end_line(line):\n",
    "                doc_lines.append(doc_line)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return doc_lines\n",
    "\n",
    "concatenate_data(filename)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}